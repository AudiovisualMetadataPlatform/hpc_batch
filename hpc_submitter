#!/bin/env python3
import argparse
import paramiko
import getpass
from pathlib import Path
import logging
import sys
import os
import socket
import time
import stat
import configparser
import tempfile
import yaml
import re
import traceback

def main():
    """
    Manage the job dropbox, submit jobs to the dropbox on HPC, and submit the
    hpc_runner to the HPC processing queue (if needed)
    """
    parser = argparse.ArgumentParser(description=main.__doc__)
    parser.add_argument("--debug", default=False, action="store_true", help="Turn on debugging")
    parser.add_argument("--nocleanup", default=False, action="store_true", help="Don't clean up the remote directories")
    parser.add_argument("--email", default=None, type=str, help="Email address for status reports")
    parser.add_argument("config", help="Configuration file")
    args = parser.parse_args()

    logging.basicConfig(level=logging.DEBUG if args.debug else logging.WARNING, 
                        stream=sys.stderr,
                        format="%(asctime)s %(levelname)s %(message)s")

    # read the configuration file
    config = configparser.ConfigParser()
    config.read(args.config)

    lockfile = Path(config['cronjob']['lockfile'])
    if lockfile.exists():
        exit(0)

    try:
        # create the lock
        with open(lockfile, mode="w") as f:
            f.write(str(os.getpid()) + "\n")

        # connect to the remote machine and go to our workspace directory
        with paramiko.SSHClient() as ssh:
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect(hostname=config['remote']['host'], 
                        port=config['remote']['port'], 
                        username=config['remote']['user'],
                        key_filename=config['remote']['key_file'],
                        passphrase=config['remote']['passphrase'])

            try:
                sftp = ssh.open_sftp()
                sftp.chdir(config['hpc_env']['workspace'])
            except Exception as e:
                raise Exception(f"Cannot change to base directory {config['hpc_env']['workspace']}: {e}")
                
            # Push any new jobs to the HPC dropbox
            dropbox = Path(config['cronjob']['dropbox'])
            for jobfile in dropbox.glob("*.job"):
                try:
                    send_job(ssh, jobfile, config['hpc_env'])
                except Exception as e:
                    logging.error(f"Cannot submit {jobfile}: {e}")

            # Submit the remote runner, if it isn't already
            submit_runner(ssh, config['hpc_env'], debug=args.debug,
                          email=args.email,
                          memory=config['hpc']['memory'],
                          partition=config['hpc']['partition'],
                          resource=config['hpc']['gres'])

            # capture any ready output
            for jobfile in dropbox.glob("*.job.submitted"):
                try:
                    collect_job(ssh, jobfile, nocleanup=args.nocleanup)
                except Exception as e:
                    logging.error(f"Cannot collect {jobfile}: {e}")
    

    except paramiko.AuthenticationException as e:
        logging.debug(e)
        exit(1)

    except Exception as e:        
        logging.error(e)
        traceback.print_exc()
    finally:
        lockfile.unlink()


def send_job(ssh, jobfile, hpc_env):
    """
    Copy the files to the HPC cluster
    """
    sftp = ssh.open_sftp()
    with open(jobfile) as f:
        job = yaml.load(f, Loader=yaml.SafeLoader)


    # Create the workspace directory by using the submitter's hostname, 
    # the inode of the submitted job file and the current time.
    workdir = f"/{socket.gethostname().split('.')[0]}-{jobfile.stat().st_ino}-{time.time()}"
    workspace = hpc_env['workspace'] + workdir
    hpc = {}
    hpc['workspace'] = workspace
    hpc['finished_file'] = f"{workspace}/finished.out"

    logging.debug(f"Creating work directory: {workspace}")
    sftp.mkdir(workspace)
    sftp.chdir(workspace)

    # copy the args into the params
    params = {}
    params.update(hpc_env)
    if 'args' in job:
        params.update(job['args'])

    # set the workspace to this job's workspace
    params['workspace'] = workspace


    # copy the input files to the workspace    
    sftp.mkdir('input')
    sftp.chdir('input')
    hpc['input_map'] = {}
    for ifile, localfile in job['input_map'].items():
        localfile = Path(localfile)
        remotefile = workspace + "/input/" + localfile.name
        hpc['input_map'][ifile] = remotefile
        logging.debug(f"Copying {localfile} to {remotefile}")
        sftp.put(localfile, remotefile)
        params[ifile] = localfile.name
    sftp.chdir("..")
    
    # create the map for the output files
    sftp.mkdir('output')
    hpc['output_map'] = {}
    for ofile, localfile in job['output_map'].items():
        localfile = Path(localfile)
        remotefile = workspace + "/output/" + localfile.name
        hpc['output_map'][ofile] = remotefile
        params[ofile] = localfile.name

    # build the job script 
    with tempfile.NamedTemporaryFile(mode="w", delete=False) as f:
        hpc_jobfile = f.name
        # Insert the run script here
        template = Path(sys.path[0], f"tools/{job['script']}.template")
        with open(template) as t:
            for l in t.readlines():
                while m := re.search(r"<<([a-zA-Z_][a-zA-Z0-9_]*?)>>", l):
                    key = m.group(1)
                    if key in params:
                        l = re.sub(f"<<{key}>>", params[key], l)
                    else:
                        logging.warning(f"Key '{key}' desired by script template, but not set in job")
                        break
                f.write(l)
        

    sftp.put(hpc_jobfile, workspace + "/job.sh")
    sftp.chmod(workspace + "/job.sh", 0o750)

    job['hpc'] = hpc
    # write the updated job file as .submitted
    with open(str(jobfile) + ".submitted", "w") as f:
        yaml.dump(job, f)
    # remove the original job file
    jobfile.unlink()
    sftp.close()


def submit_runner(ssh, hpc_env, email=None, debug=False,
             memory=32, partition=None, resource=None):
    """
    Run the hpc_queuer script on HPC which will queue the hpc_runner script
    if there are todo jobs on the HPC system and the runner isn't currently
    queued or running.
    """
    cmd = [f'{hpc_env["scripts"]}/hpc_queuer', f'--memory={memory}']
    if email:
        cmd.append(f'--email={email}')
    if partition:
        cmd.append(f"--partition {partition}")
    if resource:
        cmd.append(f"--gpu {resource}")
    if debug:
        cmd.append("--debug")
    command = " ".join(cmd)
    ssh.exec_command(command)



def collect_job(ssh, jobfile, nocleanup=False):
    """
    Check for completed jobs, copy the output files, create the results file,
    and clean up the HPC side of things.
    """
    sftp = ssh.open_sftp()
    with open(jobfile) as f:
        job = yaml.load(f, Loader=yaml.SafeLoader)

    # check to see if the finished file exists
    try:
        stat = sftp.stat(job['hpc']['finished_file'])        
    except Exception:
        logging.debug(f"Job for file file {jobfile} isn't finished yet")
        return

    results = {}
    with sftp.open(f"{job['hpc']['workspace']}/stderr.txt") as f:
        results['stderr'] = str(f.read(), encoding='utf8')
    with sftp.open(f"{job['hpc']['workspace']}/stdout.txt") as f:
        results['stdout'] = str(f.read(), encoding='utf8')
    with sftp.open(job['hpc']['finished_file']) as f:
        results['rc'] = int(f.readline())

    if results['rc'] == 0:
        results['status'] = 'ok'
        results['message'] = "Successful"
        try:
            for k, source in job['hpc']['output_map'].items():
                dest = job['output_map'][k]
                logging.debug(f"Copying {source} -> {dest}")
                sftp.get(source, dest)
        except Exception as e:
            results['status'] = 'error'
            results['message'] = 'Could not copy files'

    else:
        results['status'] = 'error'
        results['message'] = f"Remote process failed with RC {results['rc']}"    

    job['job'] = results
    # write the updated job file as .submitted
    finfile = str(jobfile).replace(".submitted", ".finished")
    with open(finfile, "w") as f:
        yaml.dump(job, f)
    # remove the submitted job file
    jobfile.unlink()

    if nocleanup:
        return

    # clean up the job and remote workspace
    logging.debug(f"Cleaning up job ({jobfile}) and workspace ({job['hpc']['workspace']}")
    clean_up(sftp, job['hpc']['workspace'])


def clean_up(sftp, dir):
    entries = list(sftp.listdir_iter(dir))
    for f in entries:
        if f.st_mode & stat.S_IFDIR:
            clean_up(sftp, f"{dir}/{f.filename}")
        else:
            logging.debug(f"Removing {dir}/{f.filename}")
            sftp.remove(f"{dir}/{f.filename}")
    logging.debug(f"Removing directory {dir}")
    sftp.rmdir(dir)

if __name__ == "__main__":
    main()